# -*- coding: utf-8 -*-
"""financial market analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jWcgRFFsxGjPbhMxUM1rzIWTdoHibWfy

### **Goal:To predict market direction and analyze the impact of macroeconomic indicators and sentiment signals on stock prices**

### **Basics**
"""

import pandas as pd
import numpy as np
from google.colab import files
d = files.upload()

#load the dataset
df = pd.read_csv('financial market  Dataset.csv')

from sklearn.preprocessing import MinMaxScaler, StandardScaler
import matplotlib.pyplot as plt

#display intial rows
df.head()

#display the shape
df.shape

#check null values
df.isnull().sum()

"""### **Handle Missing/Null Values**"""

#replacing null values
df.fillna(method='ffill', inplace = True)

#shape after replacing null values
df.shape

"""### **Convert Date to datetime and set as index**

"""

#convert to date time
#Converts the 'Date' column from a string/object format to a proper datetime format (e.g., 2021-06-01)
#Plotting time series
#Resampling (monthly/weekly data)
#Rolling averages
#Lag features
#Forecasting models

df['Date'] = pd.to_datetime(df['Date'])

#sort by date: ensures the data is in chronological order. This is important to avoid lookahead bias in machine learning models.
df.sort_values('Date', inplace = True)

#set a date as index Sets the Date column as the index of the DataFrame, allowing you to:
#Use .loc['2020-01-01'] to access rows by date
#Easily do time-based operations like .resample(), .rolling(), etc.

df.set_index('Date', inplace = True)

"""### **Normalize Numeric Features**"""

#When you normalize or scale numeric features, you transform the data to a common scale, without distorting differences in the range of values.

#This line selects the numeric columns (financial and economic indicators) that you want to normalize.

numeric_cols = ['Open', 'High', 'Low', 'Close', 'Adj_Close', 'Volume',
                'GDP', 'Inflation', 'Unemployment', 'Interest_Rate', 'CPI']

#choose a scaler
#This line chooses a method to scale the data:
#StandardScaler: Transforms data so that each column has:
#Mean = 0, Standard deviation = 1
#Best when data is normally distributed.

#MinMaxScaler: Scales all values between 0 and 1
#Useful when you want to preserve relative distances but remove scale differences.
scaler = StandardScaler()

#apply scaler
#This creates a copy of your DataFrame (so original is preserved), and applies scaling to the selected numeric_cols. Each of those columns will now be on the same scale.

df_scaled = df.copy()
df_scaled[numeric_cols] = scaler.fit_transform(df[numeric_cols])

"""### **Encode Categorical Variables**"""

#covert categorical data 'label' to numeric
df_scaled['Label'] = df['Label'].map({'Stable' : 0, 'Volatile' : 1, 'Crash' : 2})
df_scaled['Label'].value_counts()

#encode 'Event flag' to integer
df_scaled['Event_flag'] = df['Event_Flag'].astype(int)

"""### **Create Lag & Rolling Features**"""

#create lag features for the closed price
#shift(1) creates a new column that stores the previous day's Close price.
#shift(3) stores the Close price 3 days ago.
#These are called lag features â€” they help the model see patterns over time.

df_scaled['Close_Lag_1'] = df_scaled['Close'].shift(1)
df_scaled['Close_Lag_3'] = df_scaled['Close'].shift(3)

#rolling avg of 7 days
#Computes the average Close price over the last 7 days.
#Helps smooth out short-term fluctuations and shows trend.
#This helps capture the overall market momentum or trend.

df_scaled['Close_rolling_7'] = df_scaled['Close'].rolling(window=7).mean()

df_scaled.dropna(inplace=True)